{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.identity(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=np.loadtxt('ex1data1.txt',delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.1101   5.5277   8.5186   7.0032   5.8598   8.3829   7.4764   8.5781\n",
      "   6.4862   5.0546   5.7107  14.164    5.734    8.4084   5.6407   5.3794\n",
      "   6.3654   5.1301   6.4296   7.0708   6.1891  20.27     5.4901   6.3261\n",
      "   5.5649  18.945   12.828   10.957   13.176   22.203    5.2524   6.5894\n",
      "   9.2482   5.8918   8.2111   7.9334   8.0959   5.6063  12.836    6.3534\n",
      "   5.4069   6.8825  11.708    5.7737   7.8247   7.0931   5.0702   5.8014\n",
      "  11.7      5.5416   7.5402   5.3077   7.4239   7.6031   6.3328   6.3589\n",
      "   6.2742   5.6397   9.3102   9.4536   8.8254   5.1793  21.279   14.908\n",
      "  18.959    7.2182   8.2951  10.236    5.4994  20.341   10.136    7.3345\n",
      "   6.0062   7.2259   5.0269   6.5479   7.5386   5.0365  10.274    5.1077\n",
      "   5.7292   5.1884   6.3557   9.7687   6.5159   8.5172   9.1802   6.002\n",
      "   5.5204   5.0594   5.7077   7.6366   5.8707   5.3054   8.2934  13.394\n",
      "   5.4369]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x112896c88>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:,0]\n",
    "print(X)\n",
    "pyplot.scatter(data[:,0],data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/KristenMoore/Linear-Regression-in-python/blob/master/linear%20regression.py\n",
    "import numpy as np\n",
    "from numpy import zeros, ones, reshape, array, linspace, logspace, add, dot, transpose, shape, negative\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import scatter, show, title, xlabel, ylabel, plot, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy import zeros, ones, reshape, array, linspace, logspace, add, dot, transpose, shape, negative\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import scatter, show, title, xlabel, ylabel, plot, contour\n",
    "\n",
    "# ======= load and visualise the dataset =======\n",
    "data=np.loadtxt('ex1data1.txt',delimiter=',')\n",
    "plt.scatter(data[:,0],data[:,1])\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.xlabel('Population in 10,000s')\n",
    "plt.show()\n",
    "\n",
    "# ======= format the data =======\n",
    "x=data[:,0]\n",
    "Y=data[:,1]\n",
    "m=len(Y)\n",
    "y=reshape(Y,(m,1))\n",
    "\n",
    "X = ones(shape=(m, 2))\n",
    "X[:, 1] = x\n",
    "\n",
    "\n",
    "    \n",
    "# ======= define the cost function J for linear regression =======\n",
    "def cost_function(theta, X, y):\n",
    "        prediction=dot(X,theta)\n",
    "        J = (1.0/(2*m))*dot(transpose(prediction-y),(prediction-y))               \n",
    "        return J\n",
    "\n",
    "    \n",
    "# ======= Gradient Descent =======\n",
    "# define function for batch gradient descent\n",
    "def gradient_descent(theta, X, y, alpha, num_iters):\n",
    "    m=len(y)\n",
    "    J_history = zeros(shape=(num_iters, 1))\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        theta=theta-(alpha/m)*(dot(transpose(X),(dot(X,theta)-y)))\n",
    "        J_history[i] = cost_function(theta, X, y)\n",
    "    return theta, J_history\n",
    "\n",
    "# set parameters for gradient descent\n",
    "alpha = 0.01\n",
    "iterations = 1500\n",
    "theta = zeros(shape=(2, 1)) \n",
    "\n",
    "#compute and display initial cost\n",
    "print('Initial cost: '+str(cost_function(theta,X,y)[0][0]))\n",
    "\n",
    "# perform gradient descent \n",
    "theta, J_history = gradient_descent(theta, X, y, alpha, iterations)\n",
    "print('Theta found by gradient descent: '+str(theta[0][0])+', '+str(theta[1][0]))\n",
    "\n",
    "# visualise outcome\n",
    "def plot_solution(x,y,solution):\n",
    "    # create figure and axes\n",
    "    fig = plt.figure()\n",
    "    # split the page into a 1x1 array of subplots and put solution in the first one (111)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # plots scatter for x, y\n",
    "    ax.scatter(x, y, color='red', marker='o', s=100)\n",
    "    # plots solution\n",
    "    ax.plot(x, solution, color='green')\n",
    "    plt.show()\n",
    "plot_solution(x,Y,dot(X,theta))\n",
    "\n",
    "# ======= visualise cost function J over a grid of values for theta =======\n",
    "theta0_vals=linspace(-10,10,100);\n",
    "theta1_vals=linspace(-1,4,100);\n",
    "J_vals=zeros(shape=(len(theta0_vals),len(theta1_vals)));\n",
    "\n",
    "for i, elementi in enumerate(theta0_vals):\n",
    "    for j, elementj in enumerate(theta1_vals):\n",
    "        thetatest=zeros(shape=(2,1))\n",
    "        thetatest=[[elementi],[elementj]]\n",
    "        J_vals[i][j]= cost_function(thetatest, X, y)\n",
    "\n",
    "# We need to transpose J_vals before plotting it\n",
    "J_vals=transpose(J_vals)\n",
    "\n",
    "contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20))\n",
    "xlabel(r'$\\theta_0$')\n",
    "ylabel(r'$\\theta_1$')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
